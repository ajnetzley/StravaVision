{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open and read the JSON file (OLD Version, only public activities)\n",
    "# with open(\"activities_2022-07-01_to_2024-11-17.json\", \"r\") as file1:\n",
    "#     data1 = json.load(file1)\n",
    "# with open(\"activities_2020-07-18_to_2022-06-30.json\", \"r\") as file2:\n",
    "#     data2 = json.load(file2)\n",
    "# with open(\"activities_2019-07-02_to_2020-07-16.json\", \"r\") as file3:\n",
    "#     data3 = json.load(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "c:\\Users\\ajnet\\Documents\\StravaApp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"activities_data/all_activities_03-18-2025_05-25-2025.json\"))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"activities_data/all_activities_08-03-2020_12-25-2021.json\", \"r\") as file1:\n",
    "    data1 = json.load(file1)\n",
    "with open(\"activities_data/all_activities_12-25-2021_11-23-2023.json\", \"r\") as file2:\n",
    "    data2 = json.load(file2)\n",
    "with open(\"activities_data/all_activities_11-22-2023_3-18-2025.json\", \"r\") as file3:\n",
    "    data3 = json.load(file3)\n",
    "with open(\"activities_data/all-activities_07-02-2019_08-03-2020.json\", \"r\") as file4:\n",
    "    data4 = json.load(file4)\n",
    "with open(\"activities_data/all_activities_03-18-2025_05-25-2025.json\", \"r\") as file5:\n",
    "    data5 = json.load(file5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data from JSON to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant fields\n",
    "datasets = [data1, data2, data3, data4, data5]\n",
    "extracted_data = []\n",
    "for dataset in datasets:\n",
    "    for activity in dataset:\n",
    "        extracted_data.append({\n",
    "            \"id\": activity[\"id\"],\n",
    "            \"name\": activity[\"name\"],\n",
    "            \"distance\": activity[\"distance\"],\n",
    "            \"moving_time\": activity[\"moving_time\"],\n",
    "            \"elapsed_time\": activity[\"elapsed_time\"],\n",
    "            \"total_elevation_gain\": activity[\"total_elevation_gain\"],\n",
    "            \"type\": activity[\"type\"],\n",
    "            \"start_date\": activity[\"start_date\"],\n",
    "            \"start_date_local\": activity[\"start_date_local\"],\n",
    "            \"timezone\": activity[\"timezone\"],\n",
    "            \"kudos_count\": activity[\"kudos_count\"],\n",
    "            \"average_speed\": activity[\"average_speed\"],\n",
    "            \"max_speed\": activity[\"max_speed\"],\n",
    "            \"sport_type\": activity[\"sport_type\"],\n",
    "            \"elev_high\": activity[\"elev_high\"] if \"elev_high\" in activity.keys() else 0,\n",
    "            \"elev_low\": activity[\"elev_low\"] if \"elev_low\" in activity.keys() else 0\n",
    "        })\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(extracted_data)\n",
    "filtered_activities = df[[\"name\", \"start_date\", \"type\", \"sport_type\",\"distance\", \"total_elevation_gain\", \"elev_high\", \"elev_low\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardcoded adjustments for activities with mixed types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_distance_divisors = {\n",
    "    \"Ride\": 4,\n",
    "    \"MountainBikeRide\": 2.5,\n",
    "    \"GravelRide\": 3,\n",
    "    \"Run\": 1,\n",
    "    \"TrailRun\": 1,\n",
    "    \"NordicSki\": 1,\n",
    "    \"Hike\": (4/3)\n",
    "}\n",
    "\n",
    "activities_elevation_divisors = {\n",
    "    \"Ride\": 1,\n",
    "    \"MountainBikeRide\": 1,\n",
    "    \"GravelRide\": 1,\n",
    "    \"Run\": 1,\n",
    "    \"TrailRun\": 1,\n",
    "    \"NordicSki\": 1,\n",
    "    \"Hike\": (4/3)\n",
    "}\n",
    "\n",
    "partial_trail_run_adjustment = {\n",
    "    \"Mt. Teneriffe + Mt. Si\": 0.25,\n",
    "    \"Spray Park Loop\": 0.5,\n",
    "    \"Oyster Dome Loop\": 0.75,\n",
    "    \"Cutthroat Pass\": 0.25,\n",
    "    \"Trappers Peak / Thornton Lakes\": 0.25,\n",
    "    \"Trap Pass\": 0.25,\n",
    "    \"Mailbox Peak\": 0.5,\n",
    "    \"Goat Lake\": 0.75,\n",
    "    \"Green Mountain\": 0.75\n",
    "}\n",
    "\n",
    "def update_ptra(partial_trail_run_adjustment):\n",
    "        updated_ptra = {}\n",
    "        for key, value in partial_trail_run_adjustment.items():\n",
    "            if value == 0.25:\n",
    "                # if the value is 0.25, this means it is designated as a hike and has already been scaled, so we need to unscale\n",
    "                updated_ptra[key] = (4/3)*(3/4 + value/4)\n",
    "            else:\n",
    "                # other values indicate that this is categorized as a TrailRun, meaning we need to scale down.\n",
    "                updated_ptra[key] = (3/4 + value/4)\n",
    "        return updated_ptra\n",
    "\n",
    "updated_partial_trail_run_adjustment = update_ptra(partial_trail_run_adjustment)\n",
    "\n",
    "partial_gravel_ride_adjustment = {\n",
    "     \"BLOM / Island Lake\": 2.5/(0.25*2.5 + 0.75*3),\n",
    "     \"Island Lake\": 2.5/(0.25*2.5 + 0.75*3),\n",
    "     \"Waterloo + DTE\": 2.5/(0.25*2.5 + 0.75*3)\n",
    "}\n",
    "\n",
    "def convert_timestamp(timestamp):\n",
    "     return (datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%SZ\")).strftime(\"%m/%d/%y\")\n",
    "\n",
    "\n",
    "elevation_to_capacity = {\n",
    "    0: 1.0,\n",
    "    1000: 0.992,\n",
    "    2000: 0.983,\n",
    "    3000: 0.972,\n",
    "    4000: 0.959,\n",
    "    5000: 0.944,\n",
    "    6000: 0.927,\n",
    "    7000: 0.907,\n",
    "    8000: 0.886,\n",
    "    9000: 0.863,\n",
    "    10000: 0.837,\n",
    "    11000: 0.809,\n",
    "    12000: 0.78,\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the difficulty score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difficulty score by calculting the distance and elevation contributions with the sport type adjustments\n",
    "#Start by removing ski\n",
    "filtered_activities = filtered_activities[filtered_activities['sport_type'] != 'AlpineSki']\n",
    "filtered_activities[\"distance_score\"] = (df[\"distance\"]*0.000621371)/ df[\"sport_type\"].map(lambda x: activities_distance_divisors.get(x, 1))\n",
    "filtered_activities[\"distance_score\"] = (filtered_activities[\"distance_score\"]*df[\"name\"].map(lambda x: partial_gravel_ride_adjustment.get(x, 1))).round(2)\n",
    "\n",
    "filtered_activities[\"elevation_score\"] = (df[\"total_elevation_gain\"]*3*3.28084*0.001)/ df[\"sport_type\"].map(lambda x: activities_elevation_divisors.get(x, 1))\n",
    "filtered_activities[\"difficulty_score\"] = filtered_activities[\"distance_score\"] + filtered_activities[\"elevation_score\"]\n",
    "filtered_activities[\"difficulty_score_without_elevation\"] = (filtered_activities[\"difficulty_score\"]*df[\"name\"].map(lambda x: updated_partial_trail_run_adjustment.get(x, 1))).round(2)\n",
    "\n",
    "#Add adjustments for the average elevation of the activity\n",
    "filtered_activities[\"average_elevation\"] = (((filtered_activities[\"elev_high\"] + filtered_activities[\"elev_low\"])/2)*3.28084).round(2)\n",
    "filtered_activities[\"performance_capacity\"] = (filtered_activities[\"average_elevation\"].round(-3)).map(elevation_to_capacity)\n",
    "filtered_activities[\"difficulty_score\"] = (filtered_activities[\"difficulty_score_without_elevation\"] / filtered_activities[\"performance_capacity\"]).round(2)\n",
    "\n",
    "# Convert raw distance, elevation, and date to readable formats\n",
    "filtered_activities[\"Distance (miles)\"] = (filtered_activities[\"distance\"]*0.000621371).round(2)\n",
    "filtered_activities[\"Total Elevation Gain (ft)\"] = (filtered_activities[\"total_elevation_gain\"]*3.28084).round(0).astype(int)\n",
    "filtered_activities[\"Date\"] = filtered_activities[\"start_date\"].apply(convert_timestamp)\n",
    "\n",
    "filtered_activities[\"elev_high\"] = filtered_activities[\"elev_high\"]*3.28084\n",
    "# Extract only cleaned columns\n",
    "cleaned_activities = filtered_activities[[\"name\", \"Date\", \"sport_type\", \"Distance (miles)\", \"Total Elevation Gain (ft)\", \"elev_high\",\"average_elevation\", \"performance_capacity\", \"difficulty_score_without_elevation\", \"difficulty_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and analyze output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_activities[filtered_activities[\"sport_type\"].isin([\"TrailRun\", \"Hike\"])].sort_values(by=\"difficulty_score\", ascending=False).head(40)\n",
    "hardest_hiking_activities = cleaned_activities[cleaned_activities[\"sport_type\"].isin([\"TrailRun\", \"Hike\"])].sort_values(by=\"difficulty_score\", ascending=False).reset_index(drop=True)\n",
    "hardest_biking_activities = cleaned_activities[cleaned_activities[\"sport_type\"].isin([\"MountainBikeRide\", \"GravelRide\", \"Ride\"])].sort_values(by=\"difficulty_score\", ascending=False).reset_index(drop=True)\n",
    "hardest_running_activities = cleaned_activities[cleaned_activities[\"sport_type\"].isin([\"TrailRun\", \"Run\"])].sort_values(by=\"difficulty_score\", ascending=False).reset_index(drop=True)\n",
    "hardest_offroad_riding_activities = cleaned_activities[cleaned_activities[\"sport_type\"].isin([\"MountainBikeRide\", \"GravelRide\"])].sort_values(by=\"difficulty_score\", ascending=False).reset_index(drop=True)\n",
    "hardest_overall_activities = cleaned_activities.sort_values(by=\"difficulty_score\", ascending=False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DATA557",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
